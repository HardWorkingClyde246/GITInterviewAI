{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "3feef1b9-70ff-4c23-b8c0-23f730eaa54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: moviepy in c:\\users\\keyu\\anaconda3\\lib\\site-packages (1.0.3)\n",
      "Requirement already satisfied: decorator<5.0,>=4.0.2 in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from moviepy) (4.4.2)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.11.2 in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from moviepy) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.8.1 in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from moviepy) (2.31.0)\n",
      "Requirement already satisfied: proglog<=1.0.0 in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from moviepy) (0.1.10)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from moviepy) (1.26.4)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from moviepy) (2.33.1)\n",
      "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from moviepy) (0.5.1)\n",
      "Requirement already satisfied: pillow>=8.3.2 in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from imageio<3.0,>=2.5->moviepy) (10.2.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from imageio-ffmpeg>=0.2.0->moviepy) (68.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\keyu\\appdata\\roaming\\python\\python311\\site-packages (from requests<3.0,>=2.8.1->moviepy) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (2024.7.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from tqdm<5.0,>=4.11.2->moviepy) (0.4.6)\n",
      "Requirement already satisfied: SpeechRecognition in c:\\users\\keyu\\anaconda3\\lib\\site-packages (3.10.4)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from SpeechRecognition) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from SpeechRecognition) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\keyu\\appdata\\roaming\\python\\python311\\site-packages (from requests>=2.26.0->SpeechRecognition) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (2024.7.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install moviepy\n",
    "!pip install SpeechRecognition\n",
    "import moviepy.editor as mp \n",
    "import speech_recognition as sr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "c725592e-f487-44e5-b9c9-7c11d503d31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the candidate's name:  Ke Yu\n",
      "Enter candidate e-mail:  keyutan@gmail.com\n",
      "Enter candidate application position:  SE\n"
     ]
    }
   ],
   "source": [
    "candidateId = 1\n",
    "candidateName = input(\"Enter the candidate's name: \")\n",
    "candidateEmail = input(\"Enter candidate e-mail: \")\n",
    "position = input(\"Enter candidate application position: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "800ad93a-0c0e-4169-9d47-9ebd0974dca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in interviewAudio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "\n",
      "The resultant text from video is: \n",
      "\n",
      "so that's credit card accounts my first company was with convergys and I was about analyst there and then the second one was at credit corp and I was a debt collector there so I graduated with a Bachelor of science in nursing degree in St Louis University so coming from the healthcare healthcare field and entering the call centre industry was a good English learning for me I didn't have any background back then that I was grateful for the opportunity that was given to me by my previous companies and I easily learn to vote because I find myself\n"
     ]
    }
   ],
   "source": [
    "import moviepy.editor as mp\n",
    "import speech_recognition as sr\n",
    "\n",
    "try:\n",
    "    # Load the video\n",
    "    video = mp.VideoFileClip(\"interviewVideo2.mp4\")\n",
    "\n",
    "    # Extract the audio from the video\n",
    "    audio_file = video.audio\n",
    "    audio_file.write_audiofile(\"interviewAudio.wav\")\n",
    "\n",
    "    # Initialize recognizer\n",
    "    r = sr.Recognizer()\n",
    "\n",
    "    # Load the audio file\n",
    "    with sr.AudioFile(\"interviewAudio.wav\") as source:\n",
    "        data = r.record(source)\n",
    "\n",
    "    # Convert speech to text\n",
    "    text = r.recognize_google(data)\n",
    "    \n",
    "    # Print the text\n",
    "    print(\"\\nThe resultant text from video is: \\n\")\n",
    "    print(text)\n",
    "\n",
    "except sr.UnknownValueError:\n",
    "    print(\"Google Speech Recognition could not understand audio.\")\n",
    "except sr.RequestError as e:\n",
    "    print(f\"Could not request results from Google Speech Recognition service; {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "0dbbb1ff-4de5-4b63-a2bb-1bdb2c852e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install nltk\n",
    "# import nltk\n",
    "\n",
    "# nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "54d8ed12-5306-4a8f-b7bb-b587945364b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ffmpeg-python\n",
    "# !pip install pydub\n",
    "# !pip install google-cloud-speech\n",
    "# !pip install openai-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e1765d-f647-451e-9f0e-3f1a52cbed02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "f1dacd25-7203-4376-a0b1-7094a8aa3787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from moviepy.editor import VideoFileClip\n",
    "# from google.cloud import speech\n",
    "# import io\n",
    "# import whisper\n",
    "\n",
    "# def extract_audio_from_video(video_file, audio_file):\n",
    "#     try:\n",
    "#         # Load video file\n",
    "#         video = VideoFileClip(video_file)\n",
    "#         # Extract audio\n",
    "#         audio = video.audio\n",
    "#         # Write audio to file\n",
    "#         audio.write_audiofile(audio_file)\n",
    "#     except Exception as e:\n",
    "#         print(f\"An error occurred while extracting audio: {e}\")\n",
    "#         raise\n",
    "\n",
    "# def transcribe_audio_google(audio_file):\n",
    "#     client = speech.SpeechClient()\n",
    "\n",
    "#     with io.open(audio_file, \"rb\") as audio_file:\n",
    "#         content = audio_file.read()\n",
    "\n",
    "#     audio = speech.RecognitionAudio(content=content)\n",
    "#     config = speech.RecognitionConfig(\n",
    "#         encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "#         sample_rate_hertz=16000,\n",
    "#         language_code=\"en-US\",\n",
    "#     )\n",
    "\n",
    "#     response = client.recognize(config=config, audio=audio)\n",
    "\n",
    "#     transcript = \"\"\n",
    "#     for result in response.results:\n",
    "#         transcript += result.alternatives[0].transcript + \" \"\n",
    "#     return transcript\n",
    "\n",
    "# def transcribe_audio_whisper(audio_file):\n",
    "#     model = whisper.load_model(\"base\")\n",
    "#     result = model.transcribe(audio_file)\n",
    "#     return result[\"text\"]\n",
    "\n",
    "# def video_to_text(video_file, method='whisper'):\n",
    "#     audio_file = 'output_audio.wav'\n",
    "#     extract_audio_from_video(video_file, audio_file)\n",
    "    \n",
    "#     if method == 'google':\n",
    "#         return transcribe_audio_google(audio_file)\n",
    "#     elif method == 'whisper':\n",
    "#         return transcribe_audio_whisper(audio_file)\n",
    "#     else:\n",
    "#         raise ValueError(\"Invalid method specified. Use 'google' or 'whisper'.\")\n",
    "\n",
    "# # Example usage\n",
    "# video_file = r\"C:\\Users\\KEYU\\A  PythonPracticalFolder\\GoogleHackathon\\interviewVideo1.mp4\"  # Ensure this path is correct\n",
    "# transcript = video_to_text(video_file, method='whisper')\n",
    "# print(\"Transcript:\", transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "386d7397-d8b8-4a39-9ccf-e905fbd57de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\keyu\\anaconda3\\lib\\site-packages (4.43.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from transformers) (0.24.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\keyu\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.7.4)\n",
      "Requirement already satisfied: torch in c:\\users\\keyu\\anaconda3\\lib\\site-packages (2.4.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\keyu\\anaconda3\\lib\\site-packages (0.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install torch\n",
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "0a162d30-d9ee-4e04-8148-823eb33a60c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: so that's credit card accounts my first company was with convergys and I was about analyst there and then the second one was at credit corp and I was a debt collector there so I graduated with a Bachelor of science in nursing degree in St Louis University so coming from the healthcare healthcare field and entering the call centre industry was a good English learning for me I didn't have any background back then that I was grateful for the opportunity that was given to me by my previous companies and I easily learn to vote because I find myself\n",
      " \n",
      "Summary: I graduated with a Bachelor of science in nursing degree in St Louis University so coming from the healthcare healthcare field and entering the call centre industry was a good English learning for me. I didn't have any background back then that I was grateful for the opportunity that was given to me by my previous companies.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "\n",
    "# Load the pre-trained BART model and tokenizer\n",
    "model_name = 'facebook/bart-large-cnn'\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Function to summarise text\n",
    "def summarise_text(text, max_length=130, min_length=30, do_sample=False):\n",
    "    # Encode the text\n",
    "    inputs = tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "    # Generate the summary\n",
    "    summary_ids = model.generate(inputs, max_length=max_length, min_length=min_length, length_penalty=2.0, num_beams=4, early_stopping=True, do_sample=do_sample)\n",
    "    # Decode the summary\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "# Example usage\n",
    "#text = \"\"\"a few weeks ago I did a poll on LinkedIn asking you all what was the number one reason that is stopping you from using speech recognition and we'll the results kind of shocked me a little bit because a massive 75% of you said that this was down to the accuracy now you know me I love a challenge so I had to go out there and prove to you how good the accuracy is but I might have embarrassed myself a long way so just stay with me on this one let's go to the demo good day mate I apologise in advance for the absolutely awful impressions you're going to see in this demonstration full stop I am doing an Australian accent to show how good dragons accuracy is even with a variety of different dialects full stop as you can see comma dragon is still able to understand me comma even when I am embarrassing myself like this exclamation mark\n",
    "#Now I'm going to speak in an American accent comma which is a little bit easier because I can just speak like a Kardashian full stop as you can see comma dragon is understanding me word for word without a single mistake exclamation mark\n",
    "#Now I'm going back to my normal Southern English accent comma but I am speaking at a much faster pace than I usually would simply to demonstrate that the accuracy doesn't differ when you throw different challenges at the software full stop in fact comma it actually likes it when you speak in a normal manner as it helps the technology to understand the context of different words such as homophones full stop so comma if your reason for not using speech recognition is that you worry about the accuracy with your accent comma well now you have no excuse exclamation mark OK I'll be serious now I promise if you're still with me after that demo then well done because that was just the weirdest idea I've ever had but we move so sorry we do say that the more you use dragon the better the accuracy will be it learns your voice patterns and your dialect and so the more you use it the better understands you of course that equals better accuracy have a good microphone is also really key for good accuracy for example we only recommend microphones or headsets that have noise cancellation capability so in my demo I was using the Philips speech 1 which is a really great headset and of course has noise cancellation that's all for me today if we speak in these crazy accents hasn't shown you how good dragons accuracy is thinner don't know what will be honest but that is always something that you can try and that is a free proof of concept trial which means you can try the software and see it for yourself completely free of charge so there's always not as always though if you have any comments questions theories make sure you don't live in the comments because I'd love to continue talking Dragons with he dies\"\"\"\n",
    "summary = summarise_text(text)\n",
    "print(\"Original Text:\", text)\n",
    "print(\" \")\n",
    "print(\"Summary:\", summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "dcbb673e-2e78-4f67-be53-63a2427cb444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Keywords (TF-IDF): [('credit', 0.30499714066520933), ('healthcare', 0.30499714066520933), ('vote', 0.15249857033260467), ('company', 0.15249857033260467), ('didn', 0.15249857033260467)]\n",
      "<class 'list'>\n",
      "Keyword Keys: ['credit', 'healthcare', 'vote', 'company', 'didn']\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "def extract_keywords_tfidf(text, top_n=10):\n",
    "    # Create the vectorizer and transform the text data\n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    tfidf_matrix = vectorizer.fit_transform([text])\n",
    "    \n",
    "    # Get feature names and scores\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    scores = np.array(tfidf_matrix.sum(axis=0)).flatten()\n",
    "    \n",
    "    # Get top N keywords\n",
    "    top_indices = scores.argsort()[-top_n:][::-1]\n",
    "    keywords = [(feature_names[i], scores[i]) for i in top_indices]\n",
    "    \n",
    "    return keywords\n",
    "\n",
    "# Example usage\n",
    "keywords = extract_keywords_tfidf(text, top_n=5)\n",
    "print(\"Top Keywords (TF-IDF):\", keywords)\n",
    "\n",
    "print(type(keywords))\n",
    "\n",
    "# Extract 'keyword' keys and save in a new list\n",
    "keyword_keys = [keyword for keyword, score in keywords]\n",
    "print(\"Keyword Keys:\", keyword_keys)\n",
    "print(type(keyword_keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "fe013b65-b33f-4beb-9d99-d667cbd288fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# candidate_info = {}\n",
    "\n",
    "# candidate_info['CandidateID'] = candidateId\n",
    "# candidate_info['CandidateName'] = candidateName\n",
    "# candidate_info['Summary'] = summary\n",
    "# candidate_info['Keyword'] = keywords\n",
    "\n",
    "# # Print the dictionary\n",
    "# # print(candidate_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "58a1d460-7b35-4bcb-a25a-36502e8d6e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been written to 'candidates_pandas.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example dictionary\n",
    "candidates_info = [\n",
    "    {'CandidateID': candidateId, 'CandidateName': candidateName, 'CandidateEmail':candidateEmail, 'Position':position,  'Summarization': summary, 'Keyword': keyword_keys},\n",
    "    {'CandidateID': 2, 'CandidateName': 'test', 'CandidateEmail':'asdf', 'Position':'asdfs', 'Summarization': \"asdfs\", 'Keyword': \"asdfsdafsd\"},\n",
    "    {'CandidateID': 3, 'CandidateName': 'test', 'CandidateEmail':'asdfsa', 'Position':'asdfsa','Summarization': \"asdfsdaf\", 'Keyword': \"asdfasdfs\"}\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(candidates_info)\n",
    "\n",
    "csv_file_name = 'candidates_pandas.csv'\n",
    "\n",
    "df.to_csv(csv_file_name, index=False)\n",
    "\n",
    "print(f\"Data has been written to '{csv_file_name}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d6a815-8115-4ea9-9913-e70431164881",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
