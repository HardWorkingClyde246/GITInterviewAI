{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3feef1b9-70ff-4c23-b8c0-23f730eaa54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: moviepy in c:\\users\\keyu\\anaconda3\\lib\\site-packages (1.0.3)\n",
      "Requirement already satisfied: decorator<5.0,>=4.0.2 in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from moviepy) (4.4.2)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.11.2 in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from moviepy) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.8.1 in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from moviepy) (2.31.0)\n",
      "Requirement already satisfied: proglog<=1.0.0 in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from moviepy) (0.1.10)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from moviepy) (1.26.4)\n",
      "Requirement already satisfied: imageio<3.0,>=2.5 in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from moviepy) (2.33.1)\n",
      "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from moviepy) (0.5.1)\n",
      "Requirement already satisfied: pillow>=8.3.2 in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from imageio<3.0,>=2.5->moviepy) (10.2.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from imageio-ffmpeg>=0.2.0->moviepy) (68.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\keyu\\appdata\\roaming\\python\\python311\\site-packages (from requests<3.0,>=2.8.1->moviepy) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.8.1->moviepy) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from tqdm<5.0,>=4.11.2->moviepy) (0.4.6)\n",
      "Requirement already satisfied: SpeechRecognition in c:\\users\\keyu\\anaconda3\\lib\\site-packages (3.10.4)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from SpeechRecognition) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from SpeechRecognition) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\keyu\\appdata\\roaming\\python\\python311\\site-packages (from requests>=2.26.0->SpeechRecognition) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install moviepy\n",
    "!pip install SpeechRecognition\n",
    "import moviepy.editor as mp \n",
    "import speech_recognition as sr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c725592e-f487-44e5-b9c9-7c11d503d31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the candidate's name:  asdf\n",
      "Enter candidate e-mail:  asdf@gmail.com\n",
      "Enter candidate application position:  asdf\n"
     ]
    }
   ],
   "source": [
    "candidateId = 1\n",
    "candidateName = input(\"Enter the candidate's name: \")\n",
    "candidateEmail = input(\"Enter candidate e-mail: \")\n",
    "position = input(\"Enter candidate application position: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7c75cf68-318c-461d-8084-be5252e20234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Choose transcription language (type 'en' for English or 'id' for Indonesian):  en\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in interviewAudio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Google Speech Recognition could not understand audio.\n"
     ]
    }
   ],
   "source": [
    "import moviepy.editor as mp\n",
    "import speech_recognition as sr\n",
    "\n",
    "#1. Test dataset video\n",
    "#2. test indo video\n",
    "try:\n",
    "    language_choice = input(\"Choose transcription language (type 'en' for English or 'id' for Indonesian): \").strip().lower()\n",
    "    if language_choice == 'en':\n",
    "        language_code = \"en-US\"  # English language code\n",
    "    elif language_choice == 'id':\n",
    "        language_code = \"id-ID\"  # Indonesian language code\n",
    "    else:\n",
    "        raise ValueError(\"Invalid language choice. Please type 'en' for English or 'id' for Indonesian.\")\n",
    "    \n",
    "    video = mp.VideoFileClip(\"indotest-QUESTION 1 - Copy.mp4\")\n",
    "    audio_file = video.audio\n",
    "    audio_file.write_audiofile(\"interviewAudio.wav\")\n",
    "    r = sr.Recognizer()\n",
    "\n",
    "    # Load the audio file\n",
    "    with sr.AudioFile(\"interviewAudio.wav\") as source:\n",
    "        data = r.record(source)\n",
    "        \n",
    "    text = r.recognize_google(data, language=language_code)\n",
    "    print(\"\\nThe resultant text from video is: \\n\")\n",
    "    print(text)\n",
    "\n",
    "except ValueError as ve:\n",
    "    print(ve)\n",
    "except sr.UnknownValueError:\n",
    "    print(\"Google Speech Recognition could not understand audio.\")\n",
    "except sr.RequestError as e:\n",
    "    print(f\"Could not request results from Google Speech Recognition service; {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "386d7397-d8b8-4a39-9ccf-e905fbd57de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\keyu\\anaconda3\\lib\\site-packages (4.43.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from transformers) (0.24.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\keyu\\appdata\\roaming\\python\\python311\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: torch in c:\\users\\keyu\\anaconda3\\lib\\site-packages (2.4.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\keyu\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\keyu\\anaconda3\\lib\\site-packages (0.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install torch\n",
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a162d30-d9ee-4e04-8148-823eb33a60c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: so that's credit card accounts my first company was with convergys and I was about analyst there and then the second one was at credit corp and I was a debt collector there so I graduated with a Bachelor of science in nursing degree in St Louis University so coming from the healthcare healthcare field and entering the call centre industry was a good English learning for me I didn't have any background back then that I was grateful for the opportunity that was given to me by my previous companies and I easily learn to vote because myself\n",
      " \n",
      "Summary: I graduated with a Bachelor of science in nursing degree in St Louis University so coming from the healthcare healthcare field and entering the call centre industry was a good English learning for me. I didn't have any background back then that I was grateful for the opportunity that was given to me by my previous companies and I easily learn to vote because myself.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "\n",
    "# Load the pre-trained BART model and tokenizer\n",
    "model_name = 'facebook/bart-large-cnn'\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name)\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Function to summarise text\n",
    "def summarise_text(text, max_length=130, min_length=30, do_sample=False):\n",
    "    # Encode the text\n",
    "    inputs = tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "    # Generate the summary\n",
    "    summary_ids = model.generate(inputs, max_length=max_length, min_length=min_length, length_penalty=2.0, num_beams=4, early_stopping=True, do_sample=do_sample)\n",
    "    # Decode the summary\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "# Example usage\n",
    "#text = \"\"\"a few weeks ago I did a poll on LinkedIn asking you all what was the number one reason that is stopping you from using speech recognition and we'll the results kind of shocked me a little bit because a massive 75% of you said that this was down to the accuracy now you know me I love a challenge so I had to go out there and prove to you how good the accuracy is but I might have embarrassed myself a long way so just stay with me on this one let's go to the demo good day mate I apologise in advance for the absolutely awful impressions you're going to see in this demonstration full stop I am doing an Australian accent to show how good dragons accuracy is even with a variety of different dialects full stop as you can see comma dragon is still able to understand me comma even when I am embarrassing myself like this exclamation mark\n",
    "#Now I'm going to speak in an American accent comma which is a little bit easier because I can just speak like a Kardashian full stop as you can see comma dragon is understanding me word for word without a single mistake exclamation mark\n",
    "#Now I'm going back to my normal Southern English accent comma but I am speaking at a much faster pace than I usually would simply to demonstrate that the accuracy doesn't differ when you throw different challenges at the software full stop in fact comma it actually likes it when you speak in a normal manner as it helps the technology to understand the context of different words such as homophones full stop so comma if your reason for not using speech recognition is that you worry about the accuracy with your accent comma well now you have no excuse exclamation mark OK I'll be serious now I promise if you're still with me after that demo then well done because that was just the weirdest idea I've ever had but we move so sorry we do say that the more you use dragon the better the accuracy will be it learns your voice patterns and your dialect and so the more you use it the better understands you of course that equals better accuracy have a good microphone is also really key for good accuracy for example we only recommend microphones or headsets that have noise cancellation capability so in my demo I was using the Philips speech 1 which is a really great headset and of course has noise cancellation that's all for me today if we speak in these crazy accents hasn't shown you how good dragons accuracy is thinner don't know what will be honest but that is always something that you can try and that is a free proof of concept trial which means you can try the software and see it for yourself completely free of charge so there's always not as always though if you have any comments questions theories make sure you don't live in the comments because I'd love to continue talking Dragons with he dies\"\"\"\n",
    "summary = summarise_text(text)\n",
    "print(\"Original Text:\", text)\n",
    "print(\" \")\n",
    "print(\"Summary:\", summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcbb673e-2e78-4f67-be53-63a2427cb444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Keywords (TF-IDF): [('credit', 0.30499714066520933), ('healthcare', 0.30499714066520933), ('vote', 0.15249857033260467), ('company', 0.15249857033260467), ('didn', 0.15249857033260467)]\n",
      "<class 'list'>\n",
      "Keyword Keys: ['credit', 'healthcare', 'vote', 'company', 'didn']\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "def extract_keywords_tfidf(text, top_n=10):\n",
    "    # Create the vectorizer and transform the text data\n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    tfidf_matrix = vectorizer.fit_transform([text])\n",
    "    \n",
    "    # Get feature names and scores\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    scores = np.array(tfidf_matrix.sum(axis=0)).flatten()\n",
    "    \n",
    "    # Get top N keywords\n",
    "    top_indices = scores.argsort()[-top_n:][::-1]\n",
    "    keywords = [(feature_names[i], scores[i]) for i in top_indices]\n",
    "    \n",
    "    return keywords\n",
    "\n",
    "# Example usage\n",
    "keywords = extract_keywords_tfidf(text, top_n=5)\n",
    "print(\"Top Keywords (TF-IDF):\", keywords)\n",
    "\n",
    "print(type(keywords))\n",
    "\n",
    "# Extract 'keyword' keys and save in a new list\n",
    "keyword_keys = [keyword for keyword, score in keywords]\n",
    "print(\"Keyword Keys:\", keyword_keys)\n",
    "print(type(keyword_keys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe013b65-b33f-4beb-9d99-d667cbd288fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# candidate_info = {}\n",
    "\n",
    "# candidate_info['CandidateID'] = candidateId\n",
    "# candidate_info['CandidateName'] = candidateName\n",
    "# candidate_info['Summary'] = summary\n",
    "# candidate_info['Keyword'] = keywords\n",
    "\n",
    "# # Print the dictionary\n",
    "# # print(candidate_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58a1d460-7b35-4bcb-a25a-36502e8d6e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been written to 'candidates_pandas.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example dictionary\n",
    "candidates_info = [\n",
    "    {'CandidateID': candidateId, 'CandidateName': candidateName, 'CandidateEmail':candidateEmail, 'Position':position,  'Summarization': summary, 'Keyword': keyword_keys},\n",
    "    {'CandidateID': 2, 'CandidateName': 'test', 'CandidateEmail':'asdf', 'Position':'asdfs', 'Summarization': \"asdfs\", 'Keyword': \"asdfsdafsd\"},\n",
    "    {'CandidateID': 3, 'CandidateName': 'test', 'CandidateEmail':'asdfsa', 'Position':'asdfsa','Summarization': \"asdfsdaf\", 'Keyword': \"asdfasdfs\"}\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(candidates_info)\n",
    "\n",
    "csv_file_name = 'candidates_pandas.csv'\n",
    "\n",
    "df.to_csv(csv_file_name, index=False)\n",
    "\n",
    "print(f\"Data has been written to '{csv_file_name}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d6a815-8115-4ea9-9913-e70431164881",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
